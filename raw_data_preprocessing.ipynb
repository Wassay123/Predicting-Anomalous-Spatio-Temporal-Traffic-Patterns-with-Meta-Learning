{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_dimensions = {\n",
    "    'min_latitude': 40.69331716,\n",
    "    'max_latitude': 40.76915505,\n",
    "    'min_longitude': -74.01713445,\n",
    "    'max_longitude': -73.95381995\n",
    "    }\n",
    "\n",
    "grid_rows = 16\n",
    "grid_cols = 8\n",
    "\n",
    "\n",
    "class DataHandler():\n",
    "\n",
    "    def __init__(self, datapath, starttime, endtime):\n",
    "        self.df = self.load_manhattan_data(datapath)\n",
    "        self.data_intervals = self.return_timestamp_intervals(pd.to_datetime(starttime), pd.to_datetime(endtime))\n",
    "\n",
    "\n",
    "    def is_in_manhattan(self, latitude, longitude):        \n",
    "        return (manhattan_dimensions['min_latitude'] <= latitude <= manhattan_dimensions['max_latitude'] and\n",
    "                manhattan_dimensions['min_longitude'] <= longitude <= manhattan_dimensions['max_longitude'])\n",
    "    \n",
    "\n",
    "\n",
    "    def load_manhattan_data(self, datapath):\n",
    "        df = pd.read_csv(datapath)\n",
    "\n",
    "        manhattan_filter = (df.apply(lambda row: self.is_in_manhattan(row['start station latitude'], row['start station longitude']) and\n",
    "                                                 self.is_in_manhattan(row['end station latitude'], row['end station longitude']), axis=1))\n",
    "\n",
    "        df = df[manhattan_filter]\n",
    "\n",
    "        df.loc[:, 'starttime'] = pd.to_datetime(df['starttime'], errors='coerce')\n",
    "        df.loc[:, 'stoptime'] = pd.to_datetime(df['stoptime'], errors='coerce')\n",
    "\n",
    "        return df\n",
    "    \n",
    "\n",
    "\n",
    "    def return_timestamp_intervals(self, start_time, end_time):\n",
    "        dates = []\n",
    "\n",
    "        for start_date in pd.date_range(start=start_time, end=end_time, freq='30T'):\n",
    "            end_date = start_date + pd.Timedelta(hours=1)\n",
    "            \n",
    "            dates.append([start_date, end_date])\n",
    "\n",
    "        return dates\n",
    "    \n",
    "\n",
    "    \n",
    "    def create_matrix(self, station_counts):\n",
    "        # Calculate step sizes for latitude and longitude\n",
    "        lat_step = (manhattan_dimensions['max_latitude'] - manhattan_dimensions['min_latitude']) / grid_rows #roughly 0.01108 degrees\n",
    "        lon_step = (manhattan_dimensions['max_longitude'] - manhattan_dimensions['min_longitude']) / grid_cols #roughly 0.0136125 degrees\n",
    "\n",
    "        grid = np.zeros((grid_rows, grid_cols))\n",
    "\n",
    "        for index, row in station_counts.iterrows():\n",
    "            station_lat = row['station latitude']\n",
    "            station_lon = row['station longitude']\n",
    "            station_traffic = row[\"count\"]\n",
    "            \n",
    "            # Check if the current cell contains the bike station\n",
    "            for i in range(grid_rows):\n",
    "\n",
    "                for j in range(grid_cols):\n",
    "\n",
    "                    lat_min = manhattan_dimensions['min_latitude'] + i * lat_step\n",
    "                    lat_max = lat_min + lat_step\n",
    "\n",
    "                    lon_min = manhattan_dimensions['min_longitude'] + j * lon_step\n",
    "                    lon_max = lon_min + lon_step\n",
    "                    \n",
    "                    if lat_min <= station_lat < lat_max and lon_min <= station_lon < lon_max:\n",
    "                        grid[i][j] += station_traffic\n",
    "\n",
    "        # Reverse grid so that bottom of the grid now represents bottom of Manhattan\n",
    "        return grid[::-1]\n",
    "\n",
    "\n",
    "\n",
    "    def generate_inflow_matrix(self, start_interval, stop_interval):\n",
    "        # Filter rows for a specific date, e.g., '2014-01-01'\n",
    "        temp_df = self.df[(self.df['stoptime'] >= pd.to_datetime(start_interval)) & (self.df['stoptime'] <= pd.to_datetime(stop_interval))]\n",
    "\n",
    "        # Print the filtered DataFrame\n",
    "        stop_df = temp_df.drop(columns=[\n",
    "                    \"tripduration\",\n",
    "                    \"starttime\",\n",
    "                    \"start station id\", \n",
    "                    \"start station name\", \n",
    "                    \"start station latitude\", \n",
    "                    \"start station longitude\", \n",
    "                    \"bikeid\", \n",
    "                    \"usertype\", \n",
    "                    \"birth year\", \n",
    "                    \"gender\"\n",
    "                    ])\n",
    "\n",
    "        stop_df.rename(columns = {\n",
    "                                \"end station id\": \"station id\",\n",
    "                                \"end station name\": \"station name\",\n",
    "                                \"end station latitude\": \"station latitude\", \n",
    "                                \"end station longitude\": \"station longitude\"\n",
    "                                }, inplace = True)\n",
    "\n",
    "        station_counts = stop_df.groupby(['station id', 'station name', 'station latitude', 'station longitude']).size().reset_index(name='count')\n",
    "        inflow_matrix = self.create_matrix(station_counts)\n",
    "\n",
    "        return inflow_matrix   \n",
    "\n",
    "\n",
    "\n",
    "    def generate_outflow_matrix(self, start_interval, stop_interval):\n",
    "        # Filter rows for a specific date, e.g., '2014-01-01'\n",
    "        temp_df = self.df[(self.df['starttime'] >= pd.to_datetime(start_interval)) & (self.df['starttime'] <= pd.to_datetime(stop_interval))]\n",
    "\n",
    "        # Print the filtered DataFrame\n",
    "        start_df = temp_df.drop(columns=[\n",
    "                    \"tripduration\",\n",
    "                    \"stoptime\",\n",
    "                    \"end station id\", \n",
    "                    \"end station name\", \n",
    "                    \"end station latitude\", \n",
    "                    \"end station longitude\", \n",
    "                    \"bikeid\", \n",
    "                    \"usertype\", \n",
    "                    \"birth year\", \n",
    "                    \"gender\"\n",
    "                    ])\n",
    "        \n",
    "        start_df.rename(columns = {\n",
    "                          \"start station id\": \"station id\",\n",
    "                          \"start station name\": \"station name\",\n",
    "                          \"start station latitude\": \"station latitude\", \n",
    "                          \"start station longitude\": \"station longitude\"\n",
    "                          }, inplace = True)\n",
    "        \n",
    "        station_counts = start_df.groupby(['station id', 'station name', 'station latitude', 'station longitude']).size().reset_index(name='count')\n",
    "        \n",
    "        outflow_matrix = self.create_matrix(station_counts)\n",
    "\n",
    "        return outflow_matrix\n",
    "    \n",
    "        \n",
    "\n",
    "    def generate_dataset(self, filepath=\"data/processed_data.h5\"):\n",
    "        traffic_data = []\n",
    "        dates = []\n",
    "\n",
    "        for entry in range(len(self.data_intervals)):\n",
    "            start_interval, stop_interval = self.data_intervals[entry]\n",
    "\n",
    "            inflow_matrix = self.generate_inflow_matrix(start_interval, stop_interval)\n",
    "            outflow_matrix = self.generate_outflow_matrix(start_interval, stop_interval)\n",
    "\n",
    "            matrices = (outflow_matrix, inflow_matrix)\n",
    "\n",
    "            traffic_data.append(matrices)\n",
    "            dates.append(stop_interval.strftime('ISO8601'))\n",
    "\n",
    "    \n",
    "        with h5py.File(filepath, 'w') as hf:\n",
    "            # Store dates as strings\n",
    "            hf.create_dataset('timeslot', data=dates)\n",
    "            hf.create_dataset('trip', data=traffic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler_object = DataHandler(\"raw_traffic_data/201911-citibike-tripdata.csv\", \n",
    "                starttime=\"2019-11-01 00:00:00\",\n",
    "                endtime=\"2019-11-30 23:59:59\")\n",
    "\n",
    "data_handler_object.generate_dataset(\"data/201911_dataset.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
